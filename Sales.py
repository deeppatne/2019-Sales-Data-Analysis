# -*- coding: utf-8 -*-
"""Sales.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hc4CnzcF8qYJNXf9z6wkhmHLxVUc7TWv
"""

# Importing pandas and os (for using list directories)

import os
import pandas as pd

"""# QUESTIONS:
1. What was the best month for sales? How much was earned that month?
2. What city sold the most product?
3. What time should we display advertisements to maximize likelihood of customer's buying product?
4. Which are the product that are most often sold together
5. What product sold the most?
"""

# Specifying google drive path in which our dataset files are present

path = "/content/drive/My Drive/Colab Notebooks/Pandas-Data-Science-Tasks-master/SalesAnalysis/Sales_Data"

# For getting all csv files from Sales_Data folder
files = [file for file in os.listdir(path) if not file.startswith('.')]

# Creating  an empty dataframe where we can store the data of 12 months
all_months_data = pd.DataFrame()

for file in files:
    current_data = pd.read_csv(path+"/"+file)

    # Here we are concating current data in all_months_data(which is an empty dataframe)
    all_months_data = pd.concat([all_months_data, current_data])

# Merging seperate 12 files in a single file
all_months_data.to_csv("all_data.csv", index=False)

# Getting our newly created file and storing it into all_data
all_data = pd.read_csv("all_data.csv")

# Printing first 5 rows
all_data.head()

# Cleaning the Data
#  As we were trying to get the months data we found that there NaN values because of which we were not able to run certain commands
# Checking how many NaN we have
nan_df = all_data[all_data.isna().any(axis=1)]
display(nan_df.head())

# As  we see that the complete  rows are blank we will have to drop those rows
all_data = all_data.dropna(how='all') # 'all' will drop the row if the complete  row has NaN values, 'any' will drop the complete row even if it has a single NaN VALUE 
all_data.head()

# Now as we have to get the month integer we will try to get first two characters from 'Order Date' column
# Also we found that it has 'Or' value as dates so we have to exclude them
all_data = all_data[all_data['Order Date'].str[0:2]!='Or']

# As we have to find the best month for sales we have to multiply Quantity Ordered with Price Each

# Converting both these columns into integers as we have to multiply them
all_data['Quantity Ordered'] = pd.to_numeric(all_data['Quantity Ordered'])
all_data['Price Each'] = pd.to_numeric(all_data['Price Each'])

# Creating the 'Months' column by selecting first two characters
all_data['Month'] = all_data['Order Date'].str[0:2]

# Converting them into integer type
all_data['Month'] = all_data['Month'].astype('int32')
all_data.head()

# We are using this for solving question 2
# Here we have to add a City column which contains City name and State name

# Getting City name
def get_city(address):
    return address.split(",")[1].strip(" ")

# Getting State name
def get_state(address):
    return address.split(",")[2].split(" ")[1]

# Adding a new column by applying lambda function
all_data['City'] = all_data['Purchase Address'].apply(lambda x: f"{get_city(x)}  ({get_state(x)})")
all_data.head()

# Adding a new sales column 
all_data['Sales'] = all_data['Quantity Ordered'].astype('int') * all_data['Price Each'].astype('float')

# Getting the sales per month by using groupby function
all_data.groupby(['Month']).sum()

import matplotlib.pyplot as plt

#Bar graph of Months v Sales

results = all_data.groupby('Month').sum()
months = range(1,13)

# On Y axis we only want Sales data, hence results['Sales']

plt.bar(months,results['Sales'])
plt.xticks(months)
plt.ylabel('Sales in USD ($)')
plt.xlabel('Month number')
plt.show()

"""Hence we can conclud that December month has the highest number of sales.

We have also shown the bar graph of Sales for all Months
"""

# Same code as groupby months
all_data.groupby(['City']).sum()

# Again using similar code from above - Dosen't work shows improper results, so found new code from stackoverflow

import matplotlib.pyplot as plt

# Here we are plotting a graph of City v Sales

keys = [city for city, df in all_data.groupby(['City'])]

# On Y axis we only want Sales data, hence groupby(['City']).sum()['Sales']
plt.bar(keys,all_data.groupby(['City']).sum()['Sales'])
plt.ylabel('Sales in USD ($)')
plt.xlabel('Month number')
plt.xticks(keys, rotation='vertical', size=8)
plt.show()

"""From this we conclude that San Francisco city has the highest number of sales

We have also shown bar graph of Sales per City
"""

# Converting our Order Date column to datetime object
all_data['Order Date'] = pd.to_datetime(all_data['Order Date'])

# Adding a new column named 'Hours'
all_data['Hour'] = all_data['Order Date'].dt.hour

# Adding a new column named 'Minutes'
all_data['Minute'] = all_data['Order Date'].dt.minute

all_data['Count'] = 1

all_data.head()

# Reusing the  above code
hours = [hour for hour, df in all_data.groupby(['Hour'])]

# Here we will display data using Line Chart of Hours v Number of Sales

# Displaying x-axis in proper 24 hour range
hours = range(1,25)

plt.plot(hours, all_data.groupby(['Hour']).count()) #This spicific code is shown in following code
plt.xticks(hours)
plt.xlabel('Hour')
plt.ylabel('Number of Orders')
plt.grid()
plt.show()

# This shows how our data is grouped by Hour. Here we counted the number of rows by each hour
all_data.groupby(['Hour']).count()

"""From this we conclude that 1 PM and 8 PM are best times for targeting adds to customers"""

# This will check all the rows in Order ID column and check which rows are duplicated
df = all_data[all_data['Order ID'].duplicated(keep=False)] # means keep all occurences of duplicates

# We are going to group by Order ID and specifically Product column
df['Grouped'] = df.groupby('Order ID')['Product'].transform(lambda x: ','.join(x))

# Only selecting 2 columns and dropping duplicates
df2 = df[['Order ID', 'Grouped']].drop_duplicates()

# Displaying df
df.head(100)

# Displaying df2
df2.head(100)

# Now we have to count the combinations of what occurs the most

#Used Stackoverflow

# Importing combinations and counter
from itertools import combinations
from collections import Counter

count = Counter()

for row in df2['Grouped']: # Using grouped column (getting ala data  in this column)
    row_list = row.split(',') # Splitting on comma 
    count.update(Counter(combinations(row_list, 2))) # If we put '3' it will give a combination of 3


# Displaying top 10 combination of products purchased
count.most_common(10)

"""Hence, from this we can show recommendations to customers 

Eg. If a person is buying an iPhone we can show him recommendations of Lightening Charging Cable

iPhone and Lightning Charging Cable are the products which are most often sold together
"""

# Now we are trying to find which product sold the most

#Grouping by Product
product_group = all_data.groupby('Product')

# Summing and  selecting Quantity Ordered
quantity_ordered = product_group.sum()['Quantity Ordered']

quantity_ordered

# Here we are displaying a Bar Graph of Products v Ordered Quantity

keys = [pair for pair, df in product_group]  #keys = product_group
plt.bar(keys, quantity_ordered)
plt.xticks(keys, rotation='vertical', size=8)
plt.ylabel('Ordered Quantity')
plt.xlabel('Products')
plt.show()

"""Hence we can conclude AAA Batteries is the product which sold the most

#ANSWERS

1. The best month for sales was December and money earned was 4.6 million $
2. San Francisco is the city that sold the most products
3. 1 PM and 8 PM are best times for targeting adds to customers to maximize likelihood of customer's buying product
4. iPhone and Lightning Charging Cable are the products which are most often sold together
5. AAA Batteries is the product which sold the most
"""